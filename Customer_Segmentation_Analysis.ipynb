{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1dc36d",
   "metadata": {},
   "source": [
    "# ğŸ›ï¸ Customer Segmentation using K-Means Clustering\n",
    "\n",
    "This notebook demonstrates how to perform customer segmentation using K-Means clustering on the Mall Customer Segmentation dataset.\n",
    "\n",
    "## ğŸ¯ Objectives\n",
    "- Segment customers based on Annual Income and Spending Score\n",
    "- Use the Elbow method to find optimal number of clusters\n",
    "- Visualize customer segments\n",
    "- Generate business insights for targeted marketing\n",
    "\n",
    "## ğŸ“Š Dataset Overview\n",
    "The Mall Customer Segmentation Data contains information about customers including:\n",
    "- CustomerID: Unique identifier\n",
    "- Gender: Male/Female\n",
    "- Age: Customer age\n",
    "- Annual Income (k$): Customer's annual income in thousands\n",
    "- Spending Score (1-100): Score assigned based on customer behavior and spending nature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e27424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \"source\": [\n",
    "    \"# Import required libraries\n",
    "\",\n",
    "    \"import pandas as pd\n",
    "\",\n",
    "    \"import numpy as np\n",
    "\",\n",
    "    \"import matplotlib.pyplot as plt\n",
    "\",\n",
    "    \"import seaborn as sns\n",
    "\",\n",
    "    \"from sklearn.cluster import KMeans\n",
    "\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\n",
    "\",\n",
    "    \"from sklearn.metrics import silhouette_score\n",
    "\",\n",
    "    \"from mpl_toolkits.mplot3d import Axes3D\n",
    "\",\n",
    "    \"import os\n",
    "\",\n",
    "    \"import warnings\n",
    "\",\n",
    "    \"warnings.filterwarnings('ignore')\n",
    "\",\n",
    "    \"\n",
    "\",\n",
    "    \"# Set style for better plots\n",
    "\",\n",
    "    \"plt.style.use('seaborn-v0_8')\n",
    "\",\n",
    "    \"sns.set_palette(\"husl\")\n",
    "\",\n",
    "    \"\n",
    "\",\n",
    "    \"print(\"âœ… Libraries imported successfully!\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-save setup - Create results directory (remove old since results are deterministic)\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "results_dir = \"analysis_results\"\n",
    "if os.path.exists(results_dir):\n",
    "    shutil.rmtree(results_dir)\n",
    "os.makedirs(results_dir)\n",
    "\n",
    "print(f\"ğŸ“ Results will be saved to: {results_dir}\")\n",
    "print(f\"ğŸ’¡ Since analysis is deterministic, previous results will be overwritten\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f91c346",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245efaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset (with auto-generation if needed)\n",
    "def load_or_create_dataset(file_path='Mall_Customers.csv'):\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"âœ… Loading existing dataset: {file_path}\")\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        print(f\"ğŸ“¥ Dataset not found. Creating sample dataset...\")\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        n_customers = 200\n",
    "        \n",
    "        # Generate sample data\n",
    "        customer_ids = range(1, n_customers + 1)\n",
    "        genders = np.random.choice(['Male', 'Female'], n_customers, p=[0.45, 0.55])\n",
    "        ages = np.random.normal(35, 12, n_customers)\n",
    "        ages = np.clip(ages, 18, 70).astype(int)\n",
    "        \n",
    "        base_income = np.random.normal(60, 25, n_customers)\n",
    "        age_factor = (ages - 18) / 52\n",
    "        income_adjustment = age_factor * 20\n",
    "        annual_income = base_income + income_adjustment\n",
    "        annual_income = np.clip(annual_income, 15, 140).astype(int)\n",
    "        \n",
    "        spending_scores = []\n",
    "        for i in range(n_customers):\n",
    "            if annual_income[i] < 40:\n",
    "                score = np.random.uniform(1, 40) if np.random.random() < 0.7 else np.random.uniform(60, 100)\n",
    "            elif annual_income[i] < 80:\n",
    "                score = np.random.uniform(30, 70) if np.random.random() < 0.5 else np.random.uniform(10, 90)\n",
    "            else:\n",
    "                score = np.random.uniform(10, 50) if np.random.random() < 0.4 else np.random.uniform(60, 100)\n",
    "            spending_scores.append(int(score))\n",
    "        \n",
    "        data = pd.DataFrame({\n",
    "            'CustomerID': customer_ids,\n",
    "            'Gender': genders,\n",
    "            'Age': ages,\n",
    "            'Annual Income (k$)': annual_income,\n",
    "            'Spending Score (1-100)': spending_scores\n",
    "        })\n",
    "        \n",
    "        data.to_csv(file_path, index=False)\n",
    "        print(f\"âœ… Sample dataset created and saved as '{file_path}'\")\n",
    "        return data\n",
    "\n",
    "data = load_or_create_dataset()\n",
    "\n",
    "# Store dataset information\n",
    "results['dataset_info'] = {\n",
    "    'shape': data.shape,\n",
    "    'columns': list(data.columns),\n",
    "    'basic_stats': data.describe().to_dict(),\n",
    "    'missing_values': data.isnull().sum().to_dict(),\n",
    "    'data_types': data.dtypes.to_dict()\n",
    "}\n",
    "\n",
    "# Save dataset info to file\n",
    "with open(f\"{results_dir}/dataset_info.txt\", \"w\") as f:\n",
    "    f.write(\"DATASET INFORMATION\\n\")\n",
    "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "    f.write(f\"Shape: {data.shape}\\n\")\n",
    "    f.write(f\"Columns: {list(data.columns)}\\n\\n\")\n",
    "    f.write(\"Statistical Summary:\\n\")\n",
    "    f.write(data.describe().to_string())\n",
    "    f.write(\"\\n\\nMissing Values:\\n\")\n",
    "    f.write(data.isnull().sum().to_string())\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"Columns: {list(data.columns)}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ed7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nStatistical Summary:\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5984d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "missing_values = data.isnull().sum()\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"âœ… No missing values found!\")\n",
    "else:\n",
    "    print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22fb74",
   "metadata": {},
   "source": [
    "## ğŸ“Š Data Visualization and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Customer Data Exploration', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Age distribution\n",
    "axes[0, 0].hist(data['Age'], bins=20, alpha=0.7, edgecolor='black', color='skyblue')\n",
    "axes[0, 0].set_title('Age Distribution')\n",
    "axes[0, 0].set_xlabel('Age')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Annual Income distribution\n",
    "axes[0, 1].hist(data['Annual Income (k$)'], bins=20, alpha=0.7, edgecolor='black', color='lightgreen')\n",
    "axes[0, 1].set_title('Annual Income Distribution')\n",
    "axes[0, 1].set_xlabel('Annual Income (k$)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Spending Score distribution\n",
    "axes[0, 2].hist(data['Spending Score (1-100)'], bins=20, alpha=0.7, edgecolor='black', color='salmon')\n",
    "axes[0, 2].set_title('Spending Score Distribution')\n",
    "axes[0, 2].set_xlabel('Spending Score (1-100)')\n",
    "axes[0, 2].set_ylabel('Frequency')\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = data['Gender'].value_counts()\n",
    "axes[1, 0].pie(gender_counts.values, labels=gender_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "axes[1, 0].set_title('Gender Distribution')\n",
    "\n",
    "# Income vs Spending scatter plot\n",
    "axes[1, 1].scatter(data['Annual Income (k$)'], data['Spending Score (1-100)'], alpha=0.6, s=50)\n",
    "axes[1, 1].set_xlabel('Annual Income (k$)')\n",
    "axes[1, 1].set_ylabel('Spending Score (1-100)')\n",
    "axes[1, 1].set_title('Income vs Spending Score')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Age vs Income scatter plot\n",
    "axes[1, 2].scatter(data['Age'], data['Annual Income (k$)'], alpha=0.6, s=50, c='orange')\n",
    "axes[1, 2].set_xlabel('Age')\n",
    "axes[1, 2].set_ylabel('Annual Income (k$)')\n",
    "axes[1, 2].set_title('Age vs Income')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save the plot\n",
    "plt.savefig(f\"{results_dir}/01_data_exploration.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results['visualizations'].append(\"01_data_exploration.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db135526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = data[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "           square=True, linewidths=0.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix of Numeric Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "# Save the correlation matrix\n",
    "plt.savefig(f\"{results_dir}/02_correlation_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save correlation data\n",
    "correlation_matrix.to_csv(f\"{results_dir}/correlation_matrix.csv\")\n",
    "results['visualizations'].append(\"02_correlation_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31845d0a",
   "metadata": {},
   "source": [
    "## ğŸ”§ Data Preprocessing for Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3adf579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for clustering\n",
    "features = ['Annual Income (k$)', 'Spending Score (1-100)']\n",
    "X = data[features].copy()\n",
    "\n",
    "print(f\"Features selected for clustering: {features}\")\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(\"\\nFeature statistics:\")\n",
    "print(X.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1100b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"âœ… Features normalized using StandardScaler\")\n",
    "print(f\"Scaled data shape: {X_scaled.shape}\")\n",
    "print(f\"Mean of scaled features: {X_scaled.mean(axis=0)}\")\n",
    "print(f\"Std of scaled features: {X_scaled.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555b49d8",
   "metadata": {},
   "source": [
    "## ğŸ” Finding Optimal Number of Clusters\n",
    "\n",
    "We'll use two methods to determine the optimal number of clusters:\n",
    "1. **Elbow Method**: Look for the \"elbow\" in the WCSS plot\n",
    "2. **Silhouette Analysis**: Find the K with the highest silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc76407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate WCSS and Silhouette scores for different K values\n",
    "max_k = 10\n",
    "wcss = []\n",
    "silhouette_scores = []\n",
    "k_range = range(1, max_k + 1)\n",
    "\n",
    "print(f\"Testing K values from 1 to {max_k}...\")\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    \n",
    "    # Calculate silhouette score (skip for k=1 as it's undefined)\n",
    "    if k > 1:\n",
    "        score = silhouette_score(X_scaled, kmeans.labels_)\n",
    "        silhouette_scores.append(score)\n",
    "        print(f\"K={k}: WCSS={kmeans.inertia_:.2f}, Silhouette Score={score:.3f}\")\n",
    "    else:\n",
    "        silhouette_scores.append(0)\n",
    "        print(f\"K={k}: WCSS={kmeans.inertia_:.2f}\")\n",
    "\n",
    "print(\"\\nâœ… Analysis completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb65f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Elbow curve and Silhouette scores\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Elbow Method\n",
    "ax1.plot(k_range, wcss, 'bo-', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Number of Clusters (K)', fontsize=12)\n",
    "ax1.set_ylabel('WCSS (Within-Cluster Sum of Squares)', fontsize=12)\n",
    "ax1.set_title('Elbow Method for Optimal K', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations for key points\n",
    "for i, (k, w) in enumerate(zip(k_range, wcss)):\n",
    "    if k in [2, 3, 4, 5]:  # Highlight potential elbow points\n",
    "        ax1.annotate(f'K={k}\\nWCSS={w:.0f}', \n",
    "                    (k, w), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center', fontsize=10)\n",
    "\n",
    "# Silhouette Score\n",
    "ax2.plot(range(2, max_k + 1), silhouette_scores[1:], 'ro-', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Number of Clusters (K)', fontsize=12)\n",
    "ax2.set_ylabel('Silhouette Score', fontsize=12)\n",
    "ax2.set_title('Silhouette Analysis', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Find and highlight the best silhouette score\n",
    "best_k = silhouette_scores[1:].index(max(silhouette_scores[1:])) + 2\n",
    "best_score = max(silhouette_scores[1:])\n",
    "ax2.annotate(f'Best K={best_k}\\nScore={best_score:.3f}', \n",
    "            (best_k, best_score), textcoords=\"offset points\", \n",
    "            xytext=(0,15), ha='center', fontsize=12, \n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save the elbow analysis\n",
    "plt.savefig(f\"{results_dir}/03_elbow_silhouette_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Save elbow analysis data\n",
    "elbow_data = pd.DataFrame({\n",
    "    'K': k_range,\n",
    "    'WCSS': wcss,\n",
    "    'Silhouette_Score': silhouette_scores\n",
    "})\n",
    "elbow_data.to_csv(f\"{results_dir}/elbow_analysis_data.csv\", index=False)\n",
    "results['visualizations'].append(\"03_elbow_silhouette_analysis.png\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Analysis Results:\")\n",
    "print(f\"   ğŸ¯ Best K based on Silhouette Score: {best_k}\")\n",
    "print(f\"   ğŸ“ˆ Best Silhouette Score: {best_score:.3f}\")\n",
    "\n",
    "# Store optimal K results\n",
    "results['performance_metrics']['optimal_k'] = best_k\n",
    "results['performance_metrics']['best_silhouette_score'] = best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7118618",
   "metadata": {},
   "source": [
    "## ğŸ¯ Perform K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0540f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering with optimal K\n",
    "optimal_k = 4  # Based on silhouette analysis\n",
    "\n",
    "print(f\"Performing K-Means clustering with K={optimal_k}\")\n",
    "\n",
    "# Create and fit the model\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Add cluster labels to original data\n",
    "data['Cluster'] = cluster_labels\n",
    "\n",
    "# Calculate clustering performance metrics\n",
    "silhouette_avg = silhouette_score(X_scaled, cluster_labels)\n",
    "inertia = kmeans.inertia_\n",
    "\n",
    "print(f\"\\nâœ… Clustering completed!\")\n",
    "print(f\"   ğŸ“Š Silhouette Score: {silhouette_avg:.3f}\")\n",
    "print(f\"   ğŸ“Š WCSS (Inertia): {inertia:.2f}\")\n",
    "print(f\"   ğŸª Number of clusters: {optimal_k}\")\n",
    "\n",
    "# Display cluster distribution\n",
    "cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()\n",
    "print(f\"\\nğŸ“ˆ Cluster Distribution:\")\n",
    "for cluster, count in cluster_counts.items():\n",
    "    percentage = (count / len(cluster_labels)) * 100\n",
    "    print(f\"   Cluster {cluster}: {count} customers ({percentage:.1f}%)\")\n",
    "\n",
    "# Save clustered data\n",
    "data.to_csv(f\"{results_dir}/clustered_customer_data.csv\", index=False)\n",
    "\n",
    "# Store clustering results\n",
    "results['performance_metrics'].update({\n",
    "    'final_silhouette_score': silhouette_avg,\n",
    "    'inertia': inertia,\n",
    "    'n_clusters': optimal_k,\n",
    "    'cluster_distribution': cluster_counts.to_dict()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a737cd91",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Cluster Analysis and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "print(\"ğŸ“‹ DETAILED CLUSTER ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate cluster centers in original scale\n",
    "cluster_centers_scaled = kmeans.cluster_centers_\n",
    "cluster_centers_original = scaler.inverse_transform(cluster_centers_scaled)\n",
    "\n",
    "# Create DataFrame for cluster centers\n",
    "centers_df = pd.DataFrame(cluster_centers_original, columns=features)\n",
    "centers_df['Cluster'] = range(len(centers_df))\n",
    "\n",
    "print(\"\\nğŸ¯ Cluster Centers (Original Scale):\")\n",
    "print(centers_df.round(2))\n",
    "\n",
    "# Save cluster centers\n",
    "centers_df.to_csv(f\"{results_dir}/cluster_centers.csv\", index=False)\n",
    "\n",
    "# Detailed analysis for each cluster\n",
    "cluster_analysis = []\n",
    "\n",
    "for cluster_id in sorted(data['Cluster'].unique()):\n",
    "    cluster_data = data[data['Cluster'] == cluster_id]\n",
    "    \n",
    "    analysis = {\n",
    "        'Cluster': cluster_id,\n",
    "        'Count': len(cluster_data),\n",
    "        'Percentage': len(cluster_data)/len(data)*100,\n",
    "        'Avg_Age': cluster_data['Age'].mean(),\n",
    "        'Avg_Income': cluster_data['Annual Income (k$)'].mean(),\n",
    "        'Avg_Spending': cluster_data['Spending Score (1-100)'].mean(),\n",
    "        'Gender_Female_%': (cluster_data['Gender'] == 'Female').sum() / len(cluster_data) * 100\n",
    "    }\n",
    "    cluster_analysis.append(analysis)\n",
    "    \n",
    "    print(f\"\\nğŸ·ï¸ CLUSTER {cluster_id} ANALYSIS:\")\n",
    "    print(f\"   ğŸ“Š Size: {len(cluster_data)} customers ({len(cluster_data)/len(data)*100:.1f}%)\")\n",
    "    print(f\"   ğŸ‘¥ Gender: {(cluster_data['Gender'] == 'Female').sum() / len(cluster_data) * 100:.1f}% Female\")\n",
    "    print(f\"   ğŸ“ˆ Average Age: {cluster_data['Age'].mean():.1f} years\")\n",
    "    print(f\"   ğŸ’° Average Income: ${cluster_data['Annual Income (k$)'].mean():.1f}k\")\n",
    "    print(f\"   ğŸ›ï¸ Average Spending Score: {cluster_data['Spending Score (1-100)'].mean():.1f}\")\n",
    "\n",
    "# Create summary DataFrame\n",
    "cluster_summary = pd.DataFrame(cluster_analysis)\n",
    "print(\"\\nğŸ“Š Cluster Summary Table:\")\n",
    "print(cluster_summary.round(2))\n",
    "\n",
    "# Save cluster analysis\n",
    "cluster_summary.to_csv(f\"{results_dir}/cluster_analysis_summary.csv\", index=False)\n",
    "results['cluster_analysis'] = cluster_summary.to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977bba8",
   "metadata": {},
   "source": [
    "## ğŸ¨ Cluster Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive cluster visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Customer Cluster Analysis Visualizations', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Color palette for clusters\n",
    "colors = ['red', 'blue', 'green', 'purple', 'orange']\n",
    "\n",
    "# 1. Income vs Spending Score scatter plot\n",
    "ax1 = axes[0, 0]\n",
    "for i in range(optimal_k):\n",
    "    cluster_data = data[data['Cluster'] == i]\n",
    "    ax1.scatter(cluster_data['Annual Income (k$)'], \n",
    "               cluster_data['Spending Score (1-100)'], \n",
    "               c=colors[i], label=f'Cluster {i}', alpha=0.7, s=50)\n",
    "\n",
    "# Plot cluster centers\n",
    "ax1.scatter(cluster_centers_original[:, 0], cluster_centers_original[:, 1], \n",
    "           c='black', marker='X', s=200, linewidths=3, label='Centroids')\n",
    "\n",
    "ax1.set_xlabel('Annual Income (k$)')\n",
    "ax1.set_ylabel('Spending Score (1-100)')\n",
    "ax1.set_title('Income vs Spending Score')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Age vs Income scatter plot\n",
    "ax2 = axes[0, 1]\n",
    "for i in range(optimal_k):\n",
    "    cluster_data = data[data['Cluster'] == i]\n",
    "    ax2.scatter(cluster_data['Age'], cluster_data['Annual Income (k$)'], \n",
    "               c=colors[i], label=f'Cluster {i}', alpha=0.7, s=50)\n",
    "\n",
    "ax2.set_xlabel('Age')\n",
    "ax2.set_ylabel('Annual Income (k$)')\n",
    "ax2.set_title('Age vs Income by Cluster')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Cluster size distribution\n",
    "ax3 = axes[1, 0]\n",
    "cluster_counts = data['Cluster'].value_counts().sort_index()\n",
    "bars = ax3.bar(cluster_counts.index, cluster_counts.values, \n",
    "               color=[colors[i] for i in range(optimal_k)], alpha=0.7)\n",
    "ax3.set_xlabel('Cluster')\n",
    "ax3.set_ylabel('Number of Customers')\n",
    "ax3.set_title('Cluster Size Distribution')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, count in zip(bars, cluster_counts.values):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "             str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 4. Average metrics by cluster\n",
    "ax4 = axes[1, 1]\n",
    "cluster_metrics = data.groupby('Cluster')[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']].mean()\n",
    "cluster_metrics_norm = cluster_metrics.div(cluster_metrics.max()) * 100  # Normalize to 0-100 scale\n",
    "\n",
    "x = np.arange(len(cluster_metrics.index))\n",
    "width = 0.25\n",
    "\n",
    "ax4.bar(x - width, cluster_metrics_norm['Age'], width, label='Age (normalized)', alpha=0.7)\n",
    "ax4.bar(x, cluster_metrics_norm['Annual Income (k$)'], width, label='Income (normalized)', alpha=0.7)\n",
    "ax4.bar(x + width, cluster_metrics_norm['Spending Score (1-100)'], width, label='Spending Score', alpha=0.7)\n",
    "\n",
    "ax4.set_xlabel('Cluster')\n",
    "ax4.set_ylabel('Normalized Values (0-100)')\n",
    "ax4.set_title('Average Metrics by Cluster')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels([f'Cluster {i}' for i in range(optimal_k)])\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save cluster visualizations\n",
    "plt.savefig(f\"{results_dir}/04_cluster_visualizations.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results['visualizations'].append(\"04_cluster_visualizations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b24bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3D visualization if we have enough features\n",
    "fig = plt.figure(figsize=(12, 9))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Create 3D scatter plot with Age, Income, and Spending Score\n",
    "for i in range(optimal_k):\n",
    "    cluster_data = data[data['Cluster'] == i]\n",
    "    ax.scatter(cluster_data['Age'], \n",
    "               cluster_data['Annual Income (k$)'], \n",
    "               cluster_data['Spending Score (1-100)'],\n",
    "               c=colors[i], label=f'Cluster {i}', alpha=0.7, s=50)\n",
    "\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Annual Income (k$)')\n",
    "ax.set_zlabel('Spending Score (1-100)')\n",
    "ax.set_title('3D Customer Clusters\\n(Age, Income, Spending Score)', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# Save 3D visualization\n",
    "plt.savefig(f\"{results_dir}/05_3d_cluster_visualization.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results['visualizations'].append(\"05_3d_cluster_visualization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db52f044",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Business Insights and Recommendations\n",
    "\n",
    "Based on the clustering analysis, we can identify distinct customer segments and develop targeted strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate business insights\n",
    "print(\"ğŸ’¡ BUSINESS INSIGHTS & RECOMMENDATIONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define cluster characteristics based on analysis\n",
    "insights = {\n",
    "    0: {\n",
    "        'name': 'ğŸŒŸ Premium Customers',\n",
    "        'description': 'High income, high spending customers',\n",
    "        'strategies': [\n",
    "            'ğŸ¯ Target with luxury and premium products',\n",
    "            'ğŸ’ Implement exclusive loyalty programs',\n",
    "            'ğŸ† Offer VIP customer service',\n",
    "            'ğŸ“§ Send personalized high-end product recommendations'\n",
    "        ]\n",
    "    },\n",
    "    1: {\n",
    "        'name': 'ğŸ’° Budget-Conscious Customers',\n",
    "        'description': 'Lower income, conservative spending',\n",
    "        'strategies': [\n",
    "            'ğŸ·ï¸ Focus on value deals and discounts',\n",
    "            'ğŸ“¦ Promote essential and practical products',\n",
    "            'ğŸ’³ Offer payment plans and financing options',\n",
    "            'ğŸ“± Use price-sensitive marketing channels'\n",
    "        ]\n",
    "    },\n",
    "    2: {\n",
    "        'name': 'âš ï¸ Budget Enthusiasts',\n",
    "        'description': 'Moderate income but high spending tendency',\n",
    "        'strategies': [\n",
    "            'ğŸª Promote trendy and fashionable items',\n",
    "            'ğŸ“Š Encourage bulk purchases with discounts',\n",
    "            'ğŸ”„ Implement cashback and reward programs',\n",
    "            'â° Create urgency with limited-time offers'\n",
    "        ]\n",
    "    },\n",
    "    3: {\n",
    "        'name': 'ğŸ¯ Conservative High-Income',\n",
    "        'description': 'High income but conservative spending habits',\n",
    "        'strategies': [\n",
    "            'ğŸ“š Provide detailed product information and reviews',\n",
    "            'âœ¨ Emphasize quality and durability',\n",
    "            'ğŸ” Offer comparison tools and guides',\n",
    "            'ğŸ“ Use educational marketing approaches'\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Generate business insights report\n",
    "business_report = []\n",
    "insights_text = \"BUSINESS INSIGHTS & RECOMMENDATIONS\\n\" + \"=\"*60 + \"\\n\\n\"\n",
    "\n",
    "# Display insights for each cluster\n",
    "for cluster_id in sorted(data['Cluster'].unique()):\n",
    "    cluster_data = data[data['Cluster'] == cluster_id]\n",
    "    insight = insights.get(cluster_id, {'name': f'Cluster {cluster_id}', 'description': '', 'strategies': []})\n",
    "    \n",
    "    cluster_insight = {\n",
    "        'cluster_id': cluster_id,\n",
    "        'name': insight['name'],\n",
    "        'description': insight['description'],\n",
    "        'size': len(cluster_data),\n",
    "        'percentage': len(cluster_data)/len(data)*100,\n",
    "        'avg_income': cluster_data['Annual Income (k$)'].mean(),\n",
    "        'avg_spending': cluster_data['Spending Score (1-100)'].mean(),\n",
    "        'strategies': insight['strategies']\n",
    "    }\n",
    "    business_report.append(cluster_insight)\n",
    "    \n",
    "    print(f\"\\n{insight['name']} (Cluster {cluster_id}):\")\n",
    "    print(f\"   ğŸ“Š Size: {len(cluster_data)} customers ({len(cluster_data)/len(data)*100:.1f}%)\")\n",
    "    print(f\"   ğŸ“ Profile: {insight['description']}\")\n",
    "    print(f\"   ğŸ’° Avg Income: ${cluster_data['Annual Income (k$)'].mean():.0f}k\")\n",
    "    print(f\"   ğŸ›ï¸ Avg Spending Score: {cluster_data['Spending Score (1-100)'].mean():.0f}\")\n",
    "    print(f\"   ğŸ¯ Marketing Strategies:\")\n",
    "    for strategy in insight['strategies']:\n",
    "        print(f\"      {strategy}\")\n",
    "    \n",
    "    # Add to text report\n",
    "    insights_text += f\"\\n{insight['name']} (Cluster {cluster_id}):\\n\"\n",
    "    insights_text += f\"   Size: {len(cluster_data)} customers ({len(cluster_data)/len(data)*100:.1f}%)\\n\"\n",
    "    insights_text += f\"   Profile: {insight['description']}\\n\"\n",
    "    insights_text += f\"   Avg Income: ${cluster_data['Annual Income (k$)'].mean():.0f}k\\n\"\n",
    "    insights_text += f\"   Avg Spending Score: {cluster_data['Spending Score (1-100)'].mean():.0f}\\n\"\n",
    "    insights_text += f\"   Marketing Strategies:\\n\"\n",
    "    for strategy in insight['strategies']:\n",
    "        insights_text += f\"      {strategy}\\n\"\n",
    "\n",
    "print(f\"\\nğŸ¯ OVERALL STRATEGIC RECOMMENDATIONS:\")\n",
    "print(f\"   ğŸ”„ Develop cluster-specific marketing campaigns\")\n",
    "print(f\"   ğŸ“Š Monitor customer migration between clusters over time\")\n",
    "print(f\"   ğŸ¨ Customize website experience for each segment\")\n",
    "print(f\"   ğŸ“ˆ Set cluster-specific KPIs and success metrics\")\n",
    "print(f\"   ğŸ¤ Create cross-cluster upselling opportunities\")\n",
    "print(f\"   ğŸ“§ Implement segment-based email marketing\")\n",
    "\n",
    "# Add overall recommendations to text report\n",
    "insights_text += f\"\\nOVERALL STRATEGIC RECOMMENDATIONS:\\n\"\n",
    "insights_text += f\"   â€¢ Develop cluster-specific marketing campaigns\\n\"\n",
    "insights_text += f\"   â€¢ Monitor customer migration between clusters over time\\n\"\n",
    "insights_text += f\"   â€¢ Customize website experience for each segment\\n\"\n",
    "insights_text += f\"   â€¢ Set cluster-specific KPIs and success metrics\\n\"\n",
    "insights_text += f\"   â€¢ Create cross-cluster upselling opportunities\\n\"\n",
    "insights_text += f\"   â€¢ Implement segment-based email marketing\\n\"\n",
    "\n",
    "# Save business insights\n",
    "with open(f\"{results_dir}/business_insights.txt\", \"w\") as f:\n",
    "    f.write(insights_text)\n",
    "\n",
    "# Save business insights as CSV\n",
    "business_df = pd.DataFrame(business_report)\n",
    "business_df.to_csv(f\"{results_dir}/business_insights.csv\", index=False)\n",
    "\n",
    "results['business_insights'] = business_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043aec6",
   "metadata": {},
   "source": [
    "## ğŸ“Š Cluster Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary\n",
    "print(\"ğŸ“Š FINAL CLUSTERING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"âœ… Successfully segmented {len(data)} customers into {optimal_k} distinct clusters\")\n",
    "print(f\"ğŸ“ˆ Clustering Quality Metrics:\")\n",
    "print(f\"   ğŸ¯ Silhouette Score: {silhouette_avg:.3f} (Range: -1 to 1, higher is better)\")\n",
    "print(f\"   ğŸ“Š WCSS (Inertia): {inertia:.2f} (Lower is better)\")\n",
    "\n",
    "print(f\"\\nğŸª Cluster Distribution:\")\n",
    "for cluster_id in sorted(data['Cluster'].unique()):\n",
    "    count = len(data[data['Cluster'] == cluster_id])\n",
    "    percentage = count / len(data) * 100\n",
    "    print(f\"   Cluster {cluster_id}: {count:3d} customers ({percentage:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ” Key Insights:\")\n",
    "print(f\"   â€¢ Income and spending behavior show clear segmentation patterns\")\n",
    "print(f\"   â€¢ Four distinct customer personas identified\")\n",
    "print(f\"   â€¢ Each cluster requires different marketing approaches\")\n",
    "print(f\"   â€¢ Opportunity for targeted product recommendations\")\n",
    "\n",
    "print(f\"\\nğŸš€ Next Steps:\")\n",
    "print(f\"   1. Implement cluster-based marketing campaigns\")\n",
    "print(f\"   2. Develop cluster-specific product recommendations\")\n",
    "print(f\"   3. Monitor cluster performance and evolution\")\n",
    "print(f\"   4. A/B test different strategies for each segment\")\n",
    "print(f\"   5. Collect additional data to refine segmentation\")\n",
    "\n",
    "# Save final summary\n",
    "final_summary = f\"\"\"CUSTOMER SEGMENTATION ANALYSIS - FINAL SUMMARY\n",
    "{'='*60}\n",
    "\n",
    "EXECUTION DETAILS:\n",
    "Analysis Date: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Results Directory: {results_dir}\n",
    "\n",
    "DATASET OVERVIEW:\n",
    "â€¢ Total Customers: {len(data)}\n",
    "â€¢ Features Used: {features}\n",
    "â€¢ Dataset Shape: {data.shape}\n",
    "\n",
    "CLUSTERING RESULTS:\n",
    "â€¢ Optimal K: {optimal_k}\n",
    "â€¢ Silhouette Score: {silhouette_avg:.3f}\n",
    "â€¢ WCSS (Inertia): {inertia:.2f}\n",
    "\n",
    "CLUSTER DISTRIBUTION:\n",
    "\"\"\"\n",
    "\n",
    "for cluster_id in sorted(data['Cluster'].unique()):\n",
    "    count = len(data[data['Cluster'] == cluster_id])\n",
    "    percentage = count / len(data) * 100\n",
    "    final_summary += f\"â€¢ Cluster {cluster_id}: {count:3d} customers ({percentage:5.1f}%)\\n\"\n",
    "\n",
    "final_summary += f\"\"\"\n",
    "GENERATED FILES:\n",
    "â€¢ Dataset Info: dataset_info.txt\n",
    "â€¢ Clustered Data: clustered_customer_data.csv\n",
    "â€¢ Cluster Centers: cluster_centers.csv\n",
    "â€¢ Cluster Analysis: cluster_analysis_summary.csv\n",
    "â€¢ Business Insights: business_insights.txt & business_insights.csv\n",
    "â€¢ Correlation Matrix: correlation_matrix.csv\n",
    "â€¢ Elbow Analysis: elbow_analysis_data.csv\n",
    "â€¢ Visualizations: {', '.join(results['visualizations'])}\n",
    "\n",
    "KEY INSIGHTS:\n",
    "â€¢ Income and spending behavior show clear segmentation patterns\n",
    "â€¢ Four distinct customer personas identified\n",
    "â€¢ Each cluster requires different marketing approaches\n",
    "â€¢ Opportunity for targeted product recommendations\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Implement cluster-based marketing campaigns\n",
    "2. Develop cluster-specific product recommendations\n",
    "3. Monitor cluster performance and evolution\n",
    "4. A/B test different strategies for each segment\n",
    "5. Collect additional data to refine segmentation\n",
    "\n",
    "Project completed successfully! âœ¨\n",
    "\"\"\"\n",
    "\n",
    "# Save the final summary\n",
    "with open(f\"{results_dir}/00_FINAL_SUMMARY.txt\", \"w\") as f:\n",
    "    f.write(final_summary)\n",
    "\n",
    "print(f\"\\nâœ¨ Project completed successfully! âœ¨\")\n",
    "print(f\"\\nğŸ“ ALL ANALYSIS RESULTS SAVED TO: {results_dir}\")\n",
    "print(f\"ğŸ“„ Files generated: {len(results['visualizations']) + 7} files\")\n",
    "print(f\"ğŸ¨ Visualizations created: {len(results['visualizations'])} plots\")\n",
    "\n",
    "# Display comprehensive results summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ‰ COMPREHENSIVE ANALYSIS SUMMARY - ALL RESULTS AT ONCE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nğŸ“Š DATASET SUMMARY:\")\n",
    "print(f\"   â€¢ Shape: {results['dataset_info']['shape']}\")\n",
    "print(f\"   â€¢ Columns: {results['dataset_info']['columns']}\")\n",
    "print(f\"   â€¢ Missing Values: {sum(results['dataset_info']['missing_values'].values())} total\")\n",
    "\n",
    "print(f\"\\nğŸ” CLUSTERING PERFORMANCE:\")\n",
    "print(f\"   â€¢ Optimal K: {results['performance_metrics']['optimal_k']}\")\n",
    "print(f\"   â€¢ Best Silhouette Score: {results['performance_metrics']['best_silhouette_score']:.3f}\")\n",
    "print(f\"   â€¢ Final Silhouette Score: {results['performance_metrics']['final_silhouette_score']:.3f}\")\n",
    "print(f\"   â€¢ WCSS (Inertia): {results['performance_metrics']['inertia']:.2f}\")\n",
    "\n",
    "print(f\"\\nğŸª CLUSTER BREAKDOWN:\")\n",
    "for cluster_info in results['cluster_analysis']:\n",
    "    print(f\"   â€¢ Cluster {cluster_info['Cluster']}: {cluster_info['Count']} customers ({cluster_info['Percentage']:.1f}%)\")\n",
    "    print(f\"     Income: ${cluster_info['Avg_Income']:.0f}k | Spending: {cluster_info['Avg_Spending']:.0f} | Age: {cluster_info['Avg_Age']:.0f}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ BUSINESS SEGMENTS:\")\n",
    "for insight in results['business_insights']:\n",
    "    print(f\"   â€¢ {insight['name']}: {insight['description']}\")\n",
    "    print(f\"     Size: {insight['size']} customers | Strategies: {len(insight['strategies'])} recommended\")\n",
    "\n",
    "print(f\"\\nğŸ“ SAVED FILES:\")\n",
    "print(f\"   â€¢ Main Directory: {results_dir}\")\n",
    "print(f\"   â€¢ Data Files: 6 CSV/TXT files\")\n",
    "print(f\"   â€¢ Visualizations: {len(results['visualizations'])} PNG files\")\n",
    "print(f\"   â€¢ Summary Report: 00_FINAL_SUMMARY.txt\")\n",
    "\n",
    "print(f\"\\nğŸ¯ QUICK ACCESS TO KEY INSIGHTS:\")\n",
    "print(f\"   1. ğŸŒŸ Premium Customers: {[r for r in results['business_insights'] if 'Premium' in r['name']][0]['size']} customers\")\n",
    "print(f\"   2. ğŸ’° Budget-Conscious: {[r for r in results['business_insights'] if 'Budget-Conscious' in r['name']][0]['size']} customers\") \n",
    "print(f\"   3. âš ï¸ Budget Enthusiasts: {[r for r in results['business_insights'] if 'Enthusiasts' in r['name']][0]['size']} customers\")\n",
    "print(f\"   4. ğŸ¯ Conservative High-Income: {[r for r in results['business_insights'] if 'Conservative' in r['name']][0]['size']} customers\")\n",
    "\n",
    "print(f\"\\nâœ… ANALYSIS COMPLETE! All results are saved and displayed above.\")\n",
    "print(f\"ğŸ“‚ Open '{results_dir}' folder to access all generated files.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
